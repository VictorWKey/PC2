version: "3.6"
services:
  spark-worker-1:
    image: wittline/spark-worker:3.0.0
    container_name: spark-worker-1 
    network_mode: "host"
    environment:
      - SPARK_MASTER_HOST=192.168.1.10   
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=4096m    
    ports:
      - 8081:8081
    env_file:
      - ./base/hadoop/hadoop-hive.env
    volumes:
      - ./workspace:/opt/workspace
      - ./base/spark_conf/hadoop:/etc/hadoop/conf/
      - ./base/spark_conf/hive/hive-site.xml:/usr/bin/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
  datanode1:
    image: fjardim/datanode
    container_name: datanode1
    network_mode: "host"
    volumes:
      - ./base/hdfs/datanode1:/hadoop/dfs/data
    env_file:
      - ./base/hadoop/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "192.168.1.10:9870"  # Cambiar a puerto 9870
      # CORE_CONF_fs_defaultFS: "hdfs://192.168.1.10:8020"  # Añadir esta línea
      # HDFS_CONF_dfs_namenode_rpc_address: "192.168.1.10:8020"  # Añadir esta línea
    ports:
      - "9875:50075"
    deploy:
      resources:
        limits:
          memory: 500m